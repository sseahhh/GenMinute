import os
import re
import logging
from google import genai

from config import config

logger = logging.getLogger(__name__)


class ChatManager:
    """
    íšŒì˜ë¡ ê¸°ë°˜ ì±—ë´‡ ë§¤ë‹ˆì €
    SelfQueryRetrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ ,
    Gemini 2.5 Flashë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, vector_db_manager=None, retriever_type="similarity"):
        if self._initialized:
            return
        """
        Args:
            vector_db_manager (VectorDBManager, optional): ë²¡í„° DB ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤.
                                                          Noneì´ë©´ ìë™ìœ¼ë¡œ VectorDBManager() ìƒì„±.
            retriever_type (str, optional): ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì….
                                            "similarity", "mmr", "self_query", "similarity_score_threshold" ì¤‘ ì„ íƒ.
                                            Defaults to "similarity".
        """
        # vector_db_managerê°€ Noneì´ë©´ ìë™ ìƒì„± (Singletonì´ë¯€ë¡œ í•­ìƒ ê°™ì€ ì¸ìŠ¤í„´ìŠ¤)
        if vector_db_manager is None:
            from utils.vector_db_manager import VectorDBManager
            vector_db_manager = VectorDBManager()

        self.vdb_manager = vector_db_manager
        self.retriever_type = retriever_type

        # Gemini API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        api_key = config.GOOGLE_API_KEY
        if not api_key:
            raise ValueError("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.gemini_client = genai.Client(api_key=api_key)
        self.model_name = "gemini-2.5-flash"

        logger.info(f"âœ… ChatManager ì´ˆê¸°í™” ì™„ë£Œ: retriever_type='{self.retriever_type}'")

        self._initialized = True

    def search_documents(self, query: str, meeting_id: str = None, accessible_meeting_ids: list = None) -> dict:
        """
        meeting_chunksì™€ meeting_subtopicì—ì„œ ê°ê° 3ê°œì”© ê²€ìƒ‰

        Args:
            query (str): ì‚¬ìš©ì ì§ˆë¬¸
            meeting_id (str, optional): íŠ¹ì • íšŒì˜ë¡œ ì œí•œí•  ê²½ìš°
            accessible_meeting_ids (list, optional): ì‚¬ìš©ìê°€ ì ‘ê·¼ ê°€ëŠ¥í•œ meeting_id ëª©ë¡

        Returns:
            dict: {
                "chunks": [Document, ...],
                "subtopics": [Document, ...],
                "total_count": int
            }
        """
        # title í‚¤ì›Œë“œ í•„í„°ë§ ë¹„í™œì„±í™”
        # ì´ìœ : Similarity searchê°€ ì´ë¯¸ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ë¯€ë¡œ,
        #       ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ ì˜¤íˆë ¤ ì¢‹ì€ ê²°ê³¼ë¥¼ ì œê±°í•  ìˆ˜ ìˆìŒ
        title_keywords = []

        # (ì°¸ê³ ) í•„ìš”ì‹œ íŠ¹ì • íŒ¨í„´ë§Œ ì¶”ì¶œí•˜ë„ë¡ ê°œì„  ê°€ëŠ¥:
        # - ê³ ìœ ëª…ì‚¬ (ì˜ˆ: "ì‚¬ìíšŒë‹´")
        # - ë”°ì˜´í‘œë¡œ ë¬¶ì¸ ë‹¨ì–´
        # - NLP ê¸°ë°˜ ì£¼ì œì–´ ì¶”ì¶œ

        if meeting_id:
            # íŠ¹ì • ë…¸íŠ¸ë¡œ ì œí•œ (ê²€ìƒ‰ í›„ í•„í„°ë§)
            pass  # filter_criteriaëŠ” Noneìœ¼ë¡œ ìœ ì§€, ê²€ìƒ‰ í›„ meeting_idë¡œ í•„í„°ë§
        elif accessible_meeting_ids:
            # ì ‘ê·¼ ê°€ëŠ¥í•œ ë…¸íŠ¸ë“¤ë¡œ ì œí•œ (ì—¬ëŸ¬ ë…¸íŠ¸ì—ì„œ ê²€ìƒ‰)
            # Vector DBê°€ $in ì—°ì‚°ìë¥¼ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê° ë…¸íŠ¸ë³„ë¡œ ê²€ìƒ‰ í›„ ê²°í•©
            logger.info(f"ğŸ” {len(accessible_meeting_ids)}ê°œ ë…¸íŠ¸ì—ì„œ ê²€ìƒ‰ ì¤‘...")
            all_chunks = []
            all_subtopics = []

            # ì„¤ì •ëœ retriever_type ì‚¬ìš©
            try:
                chunk_result = self.vdb_manager.search(
                    db_type="chunks",
                    query=query,
                    k=len(accessible_meeting_ids) * 10,  # ë„‰ë„‰í•˜ê²Œ ê²€ìƒ‰
                    retriever_type=self.retriever_type,
                    filter_criteria=None
                )
                # ì ‘ê·¼ ê°€ëŠ¥í•œ meeting_idë¡œ í•„í„°ë§
                all_chunks = [doc for doc in chunk_result
                             if doc.metadata.get('meeting_id') in accessible_meeting_ids]

                subtopic_result = self.vdb_manager.search(
                    db_type="subtopic",
                    query=query,
                    k=len(accessible_meeting_ids) * 10,  # ë„‰ë„‰í•˜ê²Œ ê²€ìƒ‰
                    retriever_type=self.retriever_type,
                    filter_criteria=None
                )
                # ì ‘ê·¼ ê°€ëŠ¥í•œ meeting_idë¡œ í•„í„°ë§
                all_subtopics = [doc for doc in subtopic_result
                                if doc.metadata.get('meeting_id') in accessible_meeting_ids]

                # title í‚¤ì›Œë“œë¡œ ë¶€ë¶„ ì¼ì¹˜ í•„í„°ë§
                if title_keywords:
                    logger.info(f"ğŸ“Œ title í•„í„°ë§ ì ìš©: {title_keywords}")
                    filtered_chunks = []
                    for doc in all_chunks:
                        doc_title = doc.metadata.get('title', '').lower()
                        if any(keyword.lower() in doc_title for keyword in title_keywords):
                            filtered_chunks.append(doc)

                    filtered_subtopics = []
                    for doc in all_subtopics:
                        doc_title = doc.metadata.get('meeting_title', '').lower()
                        if any(keyword.lower() in doc_title for keyword in title_keywords):
                            filtered_subtopics.append(doc)

                    logger.debug(f"   í•„í„°ë§ ì „: chunks={len(all_chunks)}, subtopic={len(all_subtopics)}")
                    logger.debug(f"   í•„í„°ë§ í›„: chunks={len(filtered_chunks)}, subtopic={len(filtered_subtopics)}")

                    all_chunks = filtered_chunks
                    all_subtopics = filtered_subtopics

            except Exception as e:
                # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
                logger.warning(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                all_chunks = []
                all_subtopics = []

            # ìƒìœ„ 3ê°œì”©ë§Œ ì„ íƒ
            chunks_results = all_chunks[:3]
            subtopic_results = all_subtopics[:3]

            logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: chunks={len(chunks_results)}ê°œ, subtopic={len(subtopic_results)}ê°œ")

            return {
                "chunks": chunks_results,
                "subtopics": subtopic_results,
                "total_count": len(chunks_results) + len(subtopic_results)
            }

        try:
            # ë‹¨ì¼ ë…¸íŠ¸ ê²€ìƒ‰ ë˜ëŠ” ì „ì²´ ê²€ìƒ‰
            # ì„¤ì •ëœ retriever_type ì‚¬ìš©
            chunks_results = self.vdb_manager.search(
                db_type="chunks",
                query=query,
                k=20 if meeting_id else 10,  # ë„‰ë„‰í•˜ê²Œ ê²€ìƒ‰ í›„ í•„í„°ë§
                retriever_type=self.retriever_type,
                filter_criteria=None
            )

            subtopic_results = self.vdb_manager.search(
                db_type="subtopic",
                query=query,
                k=20 if meeting_id else 10,  # ë„‰ë„‰í•˜ê²Œ ê²€ìƒ‰ í›„ í•„í„°ë§
                retriever_type=self.retriever_type,
                filter_criteria=None
            )

            # meeting_idê°€ ì§€ì •ëœ ê²½ìš°, í•´ë‹¹ ë…¸íŠ¸ë¡œ í•„í„°ë§
            if meeting_id:
                chunks_results = [doc for doc in chunks_results
                                 if doc.metadata.get('meeting_id') == meeting_id]
                subtopic_results = [doc for doc in subtopic_results
                                   if doc.metadata.get('meeting_id') == meeting_id]

            # title í‚¤ì›Œë“œë¡œ ë¶€ë¶„ ì¼ì¹˜ í•„í„°ë§
            if title_keywords:
                logger.info(f"ğŸ“Œ title í•„í„°ë§ ì ìš©: {title_keywords}")
                filtered_chunks = []
                for doc in chunks_results:
                    doc_title = doc.metadata.get('title', '').lower()
                    # í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ titleì— í¬í•¨ë˜ë©´ ì„ íƒ
                    if any(keyword.lower() in doc_title for keyword in title_keywords):
                        filtered_chunks.append(doc)

                filtered_subtopics = []
                for doc in subtopic_results:
                    doc_title = doc.metadata.get('meeting_title', '').lower()
                    if any(keyword.lower() in doc_title for keyword in title_keywords):
                        filtered_subtopics.append(doc)

                logger.debug(f"   í•„í„°ë§ ì „: chunks={len(chunks_results)}, subtopic={len(subtopic_results)}")
                logger.debug(f"   í•„í„°ë§ í›„: chunks={len(filtered_chunks)}, subtopic={len(filtered_subtopics)}")

                chunks_results = filtered_chunks
                subtopic_results = filtered_subtopics

            # ìƒìœ„ 3ê°œë§Œ ì„ íƒ
            chunks_results = chunks_results[:3]
            subtopic_results = subtopic_results[:3]

            logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: chunks={len(chunks_results)}ê°œ, subtopic={len(subtopic_results)}ê°œ")

            return {
                "chunks": chunks_results,
                "subtopics": subtopic_results,
                "total_count": len(chunks_results) + len(subtopic_results)
            }

        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "chunks": [],
                "subtopics": [],
                "total_count": 0
            }

    def format_context(self, search_results: dict) -> str:
        """
        ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…

        Args:
            search_results (dict): search_documents()ì˜ ë°˜í™˜ê°’

        Returns:
            str: í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸
        """
        context_parts = []

        # Chunks ì¶”ê°€
        if search_results["chunks"]:
            context_parts.append("=== íšŒì˜ ëŒ€í™” ë‚´ìš© ===")
            for i, doc in enumerate(search_results["chunks"], 1):
                metadata = doc.metadata
                context_parts.append(
                    f"\n[ë¬¸ì„œ {i}]\n"
                    f"íšŒì˜: {metadata.get('title', 'N/A')}\n"
                    f"ì¼ì‹œ: {metadata.get('meeting_date', 'N/A')}\n"
                    f"ì‹œê°„: {metadata.get('start_time', 0):.0f}ì´ˆ - {metadata.get('end_time', 0):.0f}ì´ˆ\n"
                    f"ë‚´ìš©:\n{doc.page_content}\n"
                )

        # Subtopics ì¶”ê°€
        if search_results["subtopics"]:
            context_parts.append("\n=== íšŒì˜ ì£¼ì œë³„ ìš”ì•½ ===")
            for i, doc in enumerate(search_results["subtopics"], 1):
                metadata = doc.metadata
                content = doc.page_content

                # ì²« ë²ˆì§¸ ### ì œëª© ë¼ì¸ ì œê±° (êµ¬ë²„ì „ ì œëª©ì´ í¬í•¨ë  ìˆ˜ ìˆìŒ)
                content = re.sub(r'^###\s+.+?\n', '', content, count=1)

                context_parts.append(
                    f"\n[ìš”ì•½ {i}]\n"
                    f"íšŒì˜: {metadata.get('meeting_title', 'N/A')}\n"
                    f"ì¼ì‹œ: {metadata.get('meeting_date', 'N/A')}\n"
                    f"ì£¼ì œ: {metadata.get('main_topic', 'N/A')}\n"
                    f"ë‚´ìš©:\n{content}\n"
                )

        if not context_parts:
            return "ê²€ìƒ‰ëœ íšŒì˜ë¡ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

        return "\n".join(context_parts)

    def generate_answer(self, query: str, context: str) -> dict:
        """
        Gemini 2.5 Flashë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±

        Args:
            query (str): ì‚¬ìš©ì ì§ˆë¬¸
            context (str): ê²€ìƒ‰ëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸

        Returns:
            dict: {
                "success": bool,
                "answer": str,
                "error": str (optional)
            }
        """
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
ë‹¹ì‹ ì€ íšŒì˜ë¡ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì „ë¬¸ ë¹„ì„œ ì±—ë´‡ì…ë‹ˆë‹¤.

[ì§€ì‹œ ì‚¬í•­]
1. **ë°˜ë“œì‹œ** ì•„ë˜ [ê²€ìƒ‰ëœ íšŒì˜ë¡ ë‚´ìš©] **ì•ˆì—ì„œë§Œ** ì •ë³´ë¥¼ ì°¾ì•„ì„œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
2. [ê²€ìƒ‰ëœ íšŒì˜ë¡ ë‚´ìš©]ì— ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ì „í˜€ ì—†ë‹¤ë©´, "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì„ íšŒì˜ë¡ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
3. ì ˆëŒ€ë¡œ ë‹¹ì‹ ì˜ ì‚¬ì „ ì§€ì‹ì´ë‚˜ ì™¸ë¶€ ì •ë³´ë¥¼ ì‚¬ìš©í•´ì„œ ë‹µë³€ì„ ì¶”ì¸¡í•˜ê±°ë‚˜ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
4. ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì—¬ ì œê³µí•˜ì„¸ìš”.
5. **ì¤‘ìš”**: íšŒì˜ ì œëª©ê³¼ ë‚ ì§œëŠ” **ë°˜ë“œì‹œ** ë©”íƒ€ë°ì´í„°ì˜ 'íšŒì˜:' ë° 'ì¼ì‹œ:' í•„ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. ë‚´ìš©(ë³¸ë¬¸)ì— ë‚˜ì˜¤ëŠ” ì œëª©ì´ë‚˜ ë‚ ì§œëŠ” êµ¬ë²„ì „ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬´ì‹œí•˜ì„¸ìš”.

---

[ê²€ìƒ‰ëœ íšŒì˜ë¡ ë‚´ìš©]:
{context}

---

[ì‚¬ìš©ì ì§ˆë¬¸]:
{query}

---

[ë‹µë³€]:
"""

        try:
            # Gemini 2.5 Flashë¡œ ë‹µë³€ ìƒì„±
            response = self.gemini_client.models.generate_content(
                model=self.model_name,
                contents=prompt
            )

            answer = response.text.strip()

            logger.info(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(answer)}ì)")

            return {
                "success": True,
                "answer": answer
            }

        except Exception as e:
            logger.error(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": str(e)
            }

    def process_query(self, query: str, meeting_id: str = None, accessible_meeting_ids: list = None) -> dict:
        """
        ì‚¬ìš©ì ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë‹µë³€ ë°˜í™˜

        Args:
            query (str): ì‚¬ìš©ì ì§ˆë¬¸
            meeting_id (str, optional): íŠ¹ì • íšŒì˜ë¡œ ì œí•œ
            accessible_meeting_ids (list, optional): ì‚¬ìš©ìê°€ ì ‘ê·¼ ê°€ëŠ¥í•œ meeting_id ëª©ë¡

        Returns:
            dict: {
                "success": bool,
                "answer": str,
                "sources": list,
                "error": str (optional)
            }
        """
        logger.info(f"ğŸ¤– ì±—ë´‡ ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘: '{query}'")

        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_results = self.search_documents(query, meeting_id, accessible_meeting_ids)

        if search_results["total_count"] == 0:
            return {
                "success": True,
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ íšŒì˜ë¡ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": []
            }

        # 2. ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        context = self.format_context(search_results)

        # 3. ë‹µë³€ ìƒì„±
        result = self.generate_answer(query, context)

        if not result["success"]:
            return result

        # 4. ì¶œì²˜ ì •ë³´ ì¶”ê°€
        sources = []

        # Chunks ì¶œì²˜
        for doc in search_results["chunks"]:
            meta = doc.metadata
            sources.append({
                "type": "chunk",
                "meeting_id": meta.get("meeting_id"),
                "title": meta.get("title"),
                "meeting_date": meta.get("meeting_date"),
                "start_time": meta.get("start_time"),
                "end_time": meta.get("end_time")
            })

        # Subtopics ì¶œì²˜
        for doc in search_results["subtopics"]:
            meta = doc.metadata
            sources.append({
                "type": "subtopic",
                "meeting_id": meta.get("meeting_id"),
                "title": meta.get("meeting_title"),
                "meeting_date": meta.get("meeting_date"),
                "main_topic": meta.get("main_topic")
            })

        return {
            "success": True,
            "answer": result["answer"],
            "sources": sources
        }
